import discord
from discord.ext import commands
import json
import config
import ollama
import re

# L√§s FAQ-data
def load_faq():
    try:
        with open('faq.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("FAQ-fil inte hittad!")
        return {"faq": []}

# Traditionell FAQ-s√∂kning
def search_faq(query, faq_data):
    query = query.lower()
    
    for item in faq_data['faq']:
        for keyword in item['keywords']:
            if keyword.lower() in query:
                return item
    return None

# AI-assisterad s√∂kning med Ollama
async def ai_search_faq(query, faq_data):
    try:
        # Skapa kontext med alla FAQ-fr√•gor
        faq_context = "\n".join([
            f"ID {item['id']}: {item['question']} (nyckelord: {', '.join(item['keywords'])})"
            for item in faq_data['faq']
        ])
        
        prompt = f"""Du √§r en AI-assistent som hj√§lper studenter hitta r√§tt FAQ-fr√•ga.

Tillg√§ngliga FAQ-fr√•gor:
{faq_context}

Anv√§ndarens fr√•ga: "{query}"

Analysera anv√§ndarens fr√•ga och hitta det FAQ-ID som b√§st matchar. Svara ENDAST med numret (t.ex. "5") eller "0" om ingen fr√•ga passar bra.

T√§nk p√•:
- Leta efter liknande begrepp och synonymer
- F√∂rst√• intentionen bakom fr√•gan
- Svenska och engelska varianter av begrepp"""

        response = ollama.generate(
            model='llama3:latest',
            prompt=prompt,
            stream=False
        )
        
        # F√∂rs√∂k extrahera FAQ-ID fr√•n svaret
        ai_response = response['response'].strip()
        
        # Hitta nummer i svaret
        numbers = re.findall(r'\b\d+\b', ai_response)
        
        if numbers:
            faq_id = int(numbers[0])
            if faq_id > 0:
                for item in faq_data['faq']:
                    if item['id'] == faq_id:
                        return item, True  # True = AI-matchning
        
        return None, False
        
    except Exception as e:
        print(f"Ollama AI-s√∂kning misslyckades: {e}")
        return None, False

# Generera AI-svar f√∂r fr√•gor utanf√∂r FAQ
async def generate_ai_answer(query, faq_data):
    try:
        # Skapa kunskapskontext fr√•n FAQ
        knowledge_base = "\n".join([
            f"- {item['question']}: {item['answer']}"
            for item in faq_data['faq']
        ])
        
        prompt = f"""Du √§r en AI-kursassistent f√∂r en AI/ML-kurs. Baserat p√• kursinformationen nedan, svara p√• studentens fr√•ga.

Kursinformation fr√•n FAQ:
{knowledge_base}

Studentens fr√•ga: "{query}"

Instruktioner:
- Svara p√• svenska
- H√•ll svaret kort och relevant (max 200 ord)
- Om fr√•gan inte kan besvaras med kursinformationen, s√§g att du inte vet
- Referera till relevant kursmaterial n√§r det √§r l√§mpligt
- Var hj√§lpsam och uppmuntrande

Svar:"""

        response = ollama.generate(
            model='llama3:latest',
            prompt=prompt,
            stream=False
        )
        
        return response['response'].strip()
        
    except Exception as e:
        print(f"AI-svarsgenerering misslyckades: {e}")
        return None

# Skapa bot instans
intents = discord.Intents.default()
intents.message_content = True

bot = commands.Bot(command_prefix=config.COMMAND_PREFIX, intents=intents)

# N√§r bot startar
@bot.event
async def on_ready():
    print(f'{bot.user} √§r nu online!')
    
    # Testa Ollama-anslutning
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Test",
            stream=False
        )
        print("‚úÖ Ollama fungerar!")
    except Exception as e:
        print(f"‚ùå Ollama-fel: {e}")
    
    # Skicka v√§lkomstmeddelande till f√∂rsta kanalen boten kan skriva i
    for guild in bot.guilds:
        for channel in guild.text_channels:
            if channel.permissions_for(guild.me).send_messages:
                welcome_message = f"""ü§ñ **AI Kursassistent √§r nu online!**

Hej! Jag hj√§lper er med fr√•gor om AI-kursen.

**‚ú® Nu med AI-st√∂d via Ollama! ‚ú®**

**Skriv `!help` f√∂r att se alla kommandon!**

L√•t oss b√∂rja! üöÄ"""
                await channel.send(welcome_message)
                break
        break

bot.remove_command('help')

# Help kommando
@bot.command(name='help')
async def help_command(ctx):
    faq_data = load_faq()
    total_questions = len(faq_data['faq'])
    
    help_text = f"""ü§ñ **AI Kursassistent - Hj√§lp**

**Grundl√§ggande kommandon:**
- `!hello` - H√§lsning fr√•n boten
- `!deadline` - Information om projektdeadline  
- `!help` - Visa denna hj√§lp
- `!info` - Information om boten
- `!ai-status` - Kontrollera AI-status

**Fr√•gor fr√•n FAQ:**
- `!fr√•ga [din fr√•ga]` - St√§ll fr√•gor om kursen (nu med AI!)
- `!betyg` - Info om VG/G krav

**‚ú® AI-f√∂rb√§ttringar:**
- Intelligent matchning av fr√•gor
- AI-genererade svar f√∂r fr√•gor utanf√∂r FAQ
- Semantisk f√∂rst√•else av svenska och engelska

**Exempel p√• fr√•gor:**
`!fr√•ga cursor`, `!fr√•ga cnn`, `!fr√•ga mario coins`
`!fr√•ga hur fungerar transformers`, `!fr√•ga vad √§r skillnaden mellan bias och varians`

Totalt {total_questions} fr√•gor tillg√§ngliga!"""
    await ctx.send(help_text)

# Info kommando
@bot.command(name='info')
async def info_command(ctx):
    faq_data = load_faq()
    info_text = f"""‚ÑπÔ∏è **Om AI Kursassistent**

Jag √§r en Discord-bot som hj√§lper studenter med AI-kursen!

**Status:**
- Kunskapsbas: {len(faq_data['faq'])} fr√•gor och svar
- AI-motor: Ollama (lokal AI)
- Utvecklad f√∂r: AI-1 kurs 2025
- Version: 2.0 (med AI-st√∂d)

**Vad kan jag hj√§lpa till med?**
- Kursinformation och deadlines
- AI-begrepp och tekniker  
- Verktyg som Cursor och Colab
- Projektid√©er och uppgifter
- Intelligent svar p√• komplicerade fr√•gor

**Teknisk f√∂rdjupning:**
- Lokal AI-integration med Ollama
- Semantisk s√∂kning och matchning
- Multi-level svarsgenerering

Anv√§nd `!help` f√∂r att se alla kommandon!"""
    await ctx.send(info_text)

# AI-status kommando
@bot.command(name='ai-status')
async def ai_status(ctx):
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Test connection",
            stream=False
        )
        await ctx.send("‚úÖ Ollama AI fungerar! Model: llama3")
    except Exception as e:
        await ctx.send(f"‚ùå Ollama AI ej tillg√§nglig: {e}")

# Hello kommando
@bot.command(name='hello')
async def hello(ctx):
    await ctx.send(f'Hej {ctx.author.mention}! Jag √§r din AI-kursassistent! ü§ñ\n‚ú® Nu f√∂rst√§rkt med lokal AI via Ollama!')

# Deadline kommando
@bot.command(name='deadline')
async def deadline(ctx):
    faq_data = load_faq()
    for item in faq_data['faq']:
        if item['id'] == 1:  # Deadline fr√•gan
            response = f"""**{item['question']}**

{item['answer']}

*Kategori: {item['category'].replace('-', ' ').title()}*"""
            await ctx.send(response)
            return
    await ctx.send("Deadline-information ej tillg√§nglig.")

# Betyg kommando
@bot.command(name='betyg')
async def betyg(ctx):
    faq_data = load_faq()
    for item in faq_data['faq']:
        if item['id'] == 2:  # Betyg fr√•gan
            response = f"""**{item['question']}**

{item['answer']}

*Kategori: {item['category'].replace('-', ' ').title()}*"""
            await ctx.send(response)
            return
    await ctx.send("Betygsinformation ej tillg√§nglig.")

# Uppdaterat fr√•ge-kommando med AI
@bot.command(name='fr√•ga')
async def ask_question(ctx, *, question):
    # Visa att boten "t√§nker"
    thinking_msg = await ctx.send("ü§î T√§nker... (s√∂ker med AI)")
    
    faq_data = load_faq()
    
    # 1. F√∂rs√∂k traditionell FAQ-s√∂kning f√∂rst
    traditional_result = search_faq(question, faq_data)
    
    # 2. Om ingen match, f√∂rs√∂k AI-s√∂kning
    if not traditional_result:
        ai_result, is_ai_match = await ai_search_faq(question, faq_data)
        if ai_result:
            await thinking_msg.edit(content="‚úÖ Hittade svar med AI!")
            response = f"""**{ai_result['question']}** *(AI-hittad)*

{ai_result['answer']}

*Kategori: {ai_result['category'].replace('-', ' ').title()}*"""
            await ctx.send(response)
            return
    
    # 3. Om FAQ-match finns, anv√§nd den
    if traditional_result:
        await thinking_msg.edit(content="‚úÖ Hittade svar i FAQ!")
        response = f"""**{traditional_result['question']}**

{traditional_result['answer']}

*Kategori: {traditional_result['category'].replace('-', ' ').title()}*"""
        await ctx.send(response)
        return
    
    # 4. Om ingen FAQ-match, generera AI-svar
    await thinking_msg.edit(content="üß† Genererar AI-svar...")
    ai_answer = await generate_ai_answer(question, faq_data)
    if ai_answer:
        await thinking_msg.edit(content="‚úÖ AI-svar genererat!")
        response = f"""**AI-Svar:**

{ai_answer}

*Detta √§r ett AI-genererat svar baserat p√• kursmaterialet. F√∂r exakta detaljer, kolla kursdokumenten.*"""
        await ctx.send(response)
    else:
        await thinking_msg.edit(content="‚ùå Kunde inte hitta svar")
        await ctx.send("Tyv√§rr kunde jag inte hitta n√•got svar p√• din fr√•ga. F√∂rs√∂k omformulera eller anv√§nd `!help` f√∂r att se tillg√§ngliga kommandon.")

# K√∂r bot
if __name__ == "__main__":
    bot.run(config.BOT_TOKEN)
import discord
from discord.ext import commands
import json
import config
import ollama
import re

# L√§s FAQ-data
def load_faq():
    try:
        with open('faq.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("FAQ-fil inte hittad!")
        return {"faq": []}

# F√∂rb√§ttrad traditionell FAQ-s√∂kning
def search_faq(query, faq_data):
    query = query.lower().strip()
    exact_matches = []
    good_matches = []
    partial_matches = []
    
    for item in faq_data['faq']:
        for keyword in item['keywords']:
            keyword_lower = keyword.lower().strip()
            
            # 1. Exakt match (h√∂gsta prioritet)
            if keyword_lower == query:
                exact_matches.append((item, 3))  # Score: 3
                break
            
            # 2. Keyword inneh√•ller hela query (bra match)
            elif query in keyword_lower and len(query) >= 3:
                good_matches.append((item, 2))  # Score: 2
                break
            
            # 3. Query inneh√•ller keyword (s√§mre - kan ge fel resultat)
            elif keyword_lower in query and len(keyword_lower) >= 4:
                # Extra kontroll: undvik korta keywords som "ml", "g", "vg" i l√•nga queries
                if len(keyword_lower) <= 2 and len(query) > 5:
                    continue  # Skippa korta keywords i l√•nga queries
                partial_matches.append((item, 1))  # Score: 1
                break
        
        # Kontrollera √§ven mot fr√•gan sj√§lv (f√∂r b√§ttre matchning)
        question_lower = item['question'].lower()
        if query in question_lower and len(query) >= 4:
            good_matches.append((item, 2))
    
    # Sortera och returnera b√§sta match
    all_matches = exact_matches + good_matches + partial_matches
    
    if all_matches:
        # Sortera efter score (h√∂gst f√∂rst)
        all_matches.sort(key=lambda x: x[1], reverse=True)
        return all_matches[0][0]  # Returnera FAQ-item med h√∂gst score
    
    return None

# AI-assisterad s√∂kning med Ollama
async def ai_search_faq(query, faq_data):
    try:
        # Skapa kontext med alla FAQ-fr√•gor
        faq_context = "\n".join([
            f"ID {item['id']}: {item['question']} (nyckelord: {', '.join(item['keywords'])})"
            for item in faq_data['faq']
        ])
        
        prompt = f"""Du √§r en AI-assistent som hj√§lper studenter hitta r√§tt FAQ-fr√•ga.

Tillg√§ngliga FAQ-fr√•gor:
{faq_context}

Anv√§ndarens fr√•ga: "{query}"

VIKTIGA REGLER:
1. Svara ENDAST med FAQ-ID numret (t.ex. "7") eller "0" om ingen passar
2. Matcha EXAKT vad anv√§ndaren fr√•gar om, inte bara relaterade √§mnen
3. Om anv√§ndaren fr√•gar "vad √§r machine learning" - leta efter fr√•gor som SPECIFIKT handlar om machine learning/ML
4. Om anv√§ndaren fr√•gar "vad √§r CNN" - leta efter fr√•gor specifikt om CNN
5. Var mycket selektiv - hellre svara "0" √§n matcha fel fr√•ga

Vilket FAQ-ID passar EXAKT f√∂r denna fr√•ga? Svara med numret eller 0:"""

        response = ollama.generate(
            model='llama3:latest',
            prompt=prompt,
            stream=False
        )
        
        # F√∂rs√∂k extrahera FAQ-ID fr√•n svaret
        ai_response = response['response'].strip()
        
        # Hitta nummer i svaret
        numbers = re.findall(r'\b\d+\b', ai_response)
        
        if numbers:
            faq_id = int(numbers[0])
            if faq_id > 0:
                for item in faq_data['faq']:
                    if item['id'] == faq_id:
                        return item, True  # True = AI-matchning
        
        return None, False
        
    except Exception as e:
        print(f"Ollama AI-s√∂kning misslyckades: {e}")
        return None, False

# Generera AI-svar f√∂r fr√•gor utanf√∂r FAQ - STRIKT KURS-FOKUS
async def generate_ai_answer(query, faq_data):
    try:
        # Skapa kunskapskontext fr√•n FAQ
        knowledge_base = "\n".join([
            f"- {item['question']}: {item['answer']}"
            for item in faq_data['faq']
        ])
        
        prompt = f"""Du √§r en AI-kursassistent f√∂r en AI/ML-kurs. Baserat p√• kursinformationen nedan, svara p√• studentens fr√•ga.

Kursinformation fr√•n FAQ:
{knowledge_base}

Studentens fr√•ga: "{query}"

VIKTIGT: Du ska ENDAST svara p√• fr√•gor relaterade till AI/ML-kursen. Om fr√•gan inte √§r relaterad till kursen, svara:
"Den fr√•gan ligger utanf√∂r kursens omfattning. Jag hj√§lper bara med fr√•gor om AI/ML-kursen. Anv√§nd !help f√∂r att se vad jag kan hj√§lpa med."

Instruktioner f√∂r kurs-relaterade fr√•gor:
- Svara p√• svenska
- H√•ll svaret kort och relevant (max 200 ord)
- Om fr√•gan inte kan besvaras med kursinformationen, s√§g att du inte vet
- Referera till relevant kursmaterial n√§r det √§r l√§mpligt
- Var hj√§lpsam och uppmuntrande

Svar:"""

        response = ollama.generate(
            model='llama3:latest',
            prompt=prompt,
            stream=False
        )
        
        return response['response'].strip()
        
    except Exception as e:
        print(f"AI-svarsgenerering misslyckades: {e}")
        return None

# Skapa bot instans
intents = discord.Intents.default()
intents.message_content = True

bot = commands.Bot(command_prefix=config.COMMAND_PREFIX, intents=intents)

# N√§r bot startar
@bot.event
async def on_ready():
    print(f'{bot.user} √§r nu online!')
    
    # Testa Ollama-anslutning
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Test",
            stream=False
        )
        print("‚úÖ Ollama fungerar!")
    except Exception as e:
        print(f"‚ùå Ollama-fel: {e}")
    
    # Skicka v√§lkomstmeddelande till f√∂rsta kanalen boten kan skriva i
    for guild in bot.guilds:
        for channel in guild.text_channels:
            if channel.permissions_for(guild.me).send_messages:
                welcome_message = f"""ü§ñ **AI Kursassistent √§r nu online!**

Hej! Jag hj√§lper er med fr√•gor om AI-kursen.

**‚ú® Nu med AI-st√∂d via Ollama! ‚ú®**
*Fokuserad p√• kurs-relaterade fr√•gor*

**Skriv `!help` f√∂r att se alla kommandon!**

L√•t oss b√∂rja! üöÄ"""
                await channel.send(welcome_message)
                break
        break

bot.remove_command('help')

# Help kommando
@bot.command(name='help')
async def help_command(ctx):
    faq_data = load_faq()
    total_questions = len(faq_data['faq'])
    
    help_text = f"""ü§ñ **AI Kursassistent - Hj√§lp**

**Grundl√§ggande kommandon:**
- `!hello` - H√§lsning fr√•n boten
- `!deadline` - Information om projektdeadline  
- `!help` - Visa denna hj√§lp
- `!info` - Information om boten
- `!ai-status` - Kontrollera AI-status

**Fr√•gor fr√•n FAQ:**
- `!fr√•ga [din fr√•ga]` - St√§ll fr√•gor om kursen (nu med AI!)
- `!betyg` - Info om VG/G krav

**‚ú® AI-f√∂rb√§ttringar:**
- Intelligent matchning av fr√•gor
- AI-genererade svar f√∂r kurs-relaterade fr√•gor
- Semantisk f√∂rst√•else av svenska och engelska
- Strikt fokus p√• AI/ML-kursen

**Exempel p√• fr√•gor:**
`!fr√•ga cursor`, `!fr√•ga cnn`, `!fr√•ga mario coins`
`!fr√•ga hur fungerar transformers`, `!fr√•ga vad √§r skillnaden mellan bias och varians`

Totalt {total_questions} fr√•gor tillg√§ngliga!

*Jag svarar bara p√• fr√•gor relaterade till AI/ML-kursen.*"""
    await ctx.send(help_text)

# Info kommando
@bot.command(name='info')
async def info_command(ctx):
    faq_data = load_faq()
    info_text = f"""‚ÑπÔ∏è **Om AI Kursassistent**

Jag √§r en Discord-bot som hj√§lper studenter med AI-kursen!

**Status:**
- Kunskapsbas: {len(faq_data['faq'])} fr√•gor och svar
- AI-motor: Ollama (lokal AI)
- Utvecklad f√∂r: AI-1 kurs 2025
- Version: 2.1 (strikt kurs-fokus)

**Vad kan jag hj√§lpa till med?**
- Kursinformation och deadlines
- AI-begrepp och tekniker  
- Verktyg som Cursor och Colab
- Projektid√©er och uppgifter
- Intelligent svar p√• kurs-relaterade fr√•gor

**Teknisk f√∂rdjupning:**
- Lokal AI-integration med Ollama
- Semantisk s√∂kning och matchning
- Multi-level svarsgenerering
- Strikt scope-begr√§nsning till kursmaterial

**Begr√§nsningar:**
- Svarar ENDAST p√• AI/ML-kurs relaterade fr√•gor
- H√§nvisar andra fr√•gor till l√§mpliga kanaler

Anv√§nd `!help` f√∂r att se alla kommandon!"""
    await ctx.send(info_text)

# AI-status kommando
@bot.command(name='ai-status')
async def ai_status(ctx):
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Test connection",
            stream=False
        )
        await ctx.send("‚úÖ Ollama AI fungerar! Model: llama3:latest\nüéØ Konfigurerad f√∂r strikt kurs-fokus")
    except Exception as e:
        await ctx.send(f"‚ùå Ollama AI ej tillg√§nglig: {e}")

# Hello kommando
@bot.command(name='hello')
async def hello(ctx):
    await ctx.send(f'Hej {ctx.author.mention}! Jag √§r din AI-kursassistent! ü§ñ\n‚ú® Nu f√∂rst√§rkt med lokal AI via Ollama!\nüéØ Jag hj√§lper dig med AI/ML-kursen.')

# Deadline kommando
@bot.command(name='deadline')
async def deadline(ctx):
    faq_data = load_faq()
    for item in faq_data['faq']:
        if item['id'] == 1:  # Deadline fr√•gan
            response = f"""**{item['question']}**

{item['answer']}

*Kategori: {item['category'].replace('-', ' ').title()}*"""
            await ctx.send(response)
            return
    await ctx.send("Deadline-information ej tillg√§nglig.")

# Betyg kommando
@bot.command(name='betyg')
async def betyg(ctx):
    faq_data = load_faq()
    for item in faq_data['faq']:
        if item['id'] == 2:  # Betyg fr√•gan
            response = f"""**{item['question']}**

{item['answer']}

*Kategori: {item['category'].replace('-', ' ').title()}*"""
            await ctx.send(response)
            return
    await ctx.send("Betygsinformation ej tillg√§nglig.")

# Uppdaterat fr√•ge-kommando med AI - FIXAD LOGIK
@bot.command(name='fr√•ga')
async def ask_question(ctx, *, question):
    # Visa att boten "t√§nker"
    thinking_msg = await ctx.send("ü§î T√§nker... (s√∂ker med AI)")
    
    faq_data = load_faq()
    
    # 1. F√∂rs√∂k f√∂rb√§ttrad traditionell FAQ-s√∂kning f√∂rst
    traditional_result = search_faq(question, faq_data)
    
    # 2. Om traditionell FAQ-s√∂kning hittade n√•got, anv√§nd det direkt
    if traditional_result:
        await thinking_msg.edit(content="‚úÖ Hittade svar i FAQ!")
        response = f"""**{traditional_result['question']}**

{traditional_result['answer']}

*Kategori: {traditional_result['category'].replace('-', ' ').title()}*"""
        await ctx.send(response)
        return
    
    # 3. Om ingen traditionell match, f√∂rs√∂k AI-s√∂kning
    ai_result, is_ai_match = await ai_search_faq(question, faq_data)
    if ai_result:
        await thinking_msg.edit(content="‚úÖ Hittade svar med AI!")
        response = f"""**{ai_result['question']}** *(AI-hittad)*

{ai_result['answer']}

*Kategori: {ai_result['category'].replace('-', ' ').title()}*"""
        await ctx.send(response)
        return
    
    # 4. Om ingen FAQ-match, generera AI-svar (med kurs-fokus)
    await thinking_msg.edit(content="üß† Genererar AI-svar...")
    ai_answer = await generate_ai_answer(question, faq_data)
    if ai_answer:
        await thinking_msg.edit(content="‚úÖ AI-svar genererat!")
        response = f"""**AI-Svar:**

{ai_answer}

*Detta √§r ett AI-genererat svar baserat p√• kursmaterialet. F√∂r exakta detaljer, kolla kursdokumenten.*"""
        await ctx.send(response)
    else:
        await thinking_msg.edit(content="‚ùå Kunde inte hitta svar")
        await ctx.send("Tyv√§rr kunde jag inte hitta n√•got svar p√• din fr√•ga. F√∂rs√∂k omformulera eller anv√§nd `!help` f√∂r att se tillg√§ngliga kommandon.")

# K√∂r bot
if __name__ == "__main__":
    bot.run(config.BOT_TOKEN)
import discord
from discord.ext import commands
import json
import config
import ollama
import re

# Load FAQ data
def load_faq():
    try:
        with open('faq.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("FAQ file not found!")
        return {"faq": []}

# Enhanced AI answer generation with comprehensive knowledge
async def generate_ai_answer(query, faq_data):
    try:
        # Create comprehensive knowledge base from FAQ
        knowledge_base = "\n\n".join([
            f"Fr√•ga: {item['question']}\nSvar: {item['answer']}\nKategori: {item['category']}\nNyckelord: {', '.join(item['keywords'])}"
            for item in faq_data['faq']
        ])
        
        # Enhanced prompt with more context and clearer instructions
        prompt = f"""Du √§r en intelligent AI-kursassistent f√∂r en AI/ML-kurs p√• svenska. Du ska ALLTID ge ett hj√§lpsamt svar.

FULL KURSINFORMATION:
{knowledge_base}

EXTRA KUNSKAP:
- Cursor √§r en AI-f√∂rst√§rkt kodeditor/IDE som anv√§nder AI f√∂r att hj√§lpa med programmering
- AI-f√∂rst√§rkta IDEer anv√§nder spr√•kmodeller f√∂r kodkomplettering, debugging och f√∂rklaringar
- Transformers √§r en neural n√§tverksarkitektur som revolutionerat NLP och AI
- CNN (Convolutional Neural Networks) anv√§nds fr√§mst f√∂r bildanalys
- Perceptroner √§r enkla neurala n√§tverk med en eller f√• lager
- Backpropagation √§r algoritmen som tr√§nar neurala n√§tverk genom att r√§kna gradienter bakl√§nges

STUDENTENS FR√ÖGA: "{query}"

INSTRUKTIONER:
- Svara ALLTID p√• svenska med ett komplett och pedagogiskt svar
- Anv√§nd kursinformationen n√§r den √§r relevant
- F√∂r allm√§nna AI/ML-fr√•gor: ge tydliga, l√§tta att f√∂rst√• f√∂rklaringar
- F√∂rklara tekniska termer p√• ett enkelt s√§tt
- H√•ll svaret under 300 ord men g√∂r det fullst√§ndigt
- Var uppmuntrande och hj√§lpsam
- Strukturera svaret tydligt

VIKTIGT: Ge ALDRIG svaret "jag vet inte" - hitta alltid n√•got relevant att s√§ga!

SVAR:"""

        response = ollama.generate(
            model='llama3:latest',
            prompt=prompt,
            stream=False
        )
        
        return response['response'].strip()
        
    except Exception as e:
        print(f"AI answer generation failed: {e}")
        return f"Tyv√§rr uppstod ett tekniskt fel med AI-svaret. Prova att st√§lla fr√•gan igen eller anv√§nd !help f√∂r att se tillg√§ngliga kommandon."

# Main question processing function - simplified without if-statements
async def process_question(ctx, question):
    thinking_msg = await ctx.send("ü§î T√§nker...")
    
    faq_data = load_faq()
    
    # Always generate AI answer with all available information
    ai_answer = await generate_ai_answer(question, faq_data)
    
    await thinking_msg.edit(content="‚úÖ Svar klart!")
    
    # Format response
    response = f"""**AI-svar:**

{ai_answer}

*Genererat av AI-kursassistent*"""
    
    # Handle Discord message length limit (2000 chars)
    if len(response) > 1900:
        max_answer_length = 1900 - len("**AI-svar:**\n\n") - len("\n\n*Genererat av AI-kursassistent*") - 10
        truncated_answer = ai_answer[:max_answer_length] + "..."
        response = f"""**AI-svar:**

{truncated_answer}

*Genererat av AI-kursassistent*"""
    
    await ctx.send(response)

# Create bot instance
intents = discord.Intents.default()
intents.message_content = True

bot = commands.Bot(command_prefix=config.COMMAND_PREFIX, intents=intents)

# When bot starts
@bot.event
async def on_ready():
    print(f'{bot.user} is now online!')
    
    # Test Ollama connection
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Hej, svara bara 'Ollama fungerar p√• svenska!'",
            stream=False
        )
        print("‚úÖ Ollama fungerar!")
    except Exception as e:
        print(f"‚ùå Ollama error: {e}")
    
    # Send welcome message
    for guild in bot.guilds:
        for channel in guild.text_channels:
            if channel.permissions_for(guild.me).send_messages:
                welcome_message = f"""ü§ñ **AI Kursassistent √§r online!**

**St√§ll fr√•gor om AI/ML-kursen:**
‚Ä¢ `!vad √§r llm?`
‚Ä¢ `!f√∂rklara transformers`
‚Ä¢ `!vad √§r CNN?`
‚Ä¢ `!deadline`
‚Ä¢ `!betyg`

**Kommandon:** `!help` `!info` `!ai-status` """
                await channel.send(welcome_message)
                break
        break

# Remove default help command
bot.remove_command('help')

# Simplified error handler - processes ALL unknown commands as questions
@bot.event
async def on_command_error(ctx, error):
    if isinstance(error, commands.CommandNotFound):
        message_content = ctx.message.content
        if message_content.startswith(config.COMMAND_PREFIX):
            question_part = message_content[len(config.COMMAND_PREFIX):].strip()
            
            # Process ANY text after the prefix as a question
            await process_question(ctx, question_part)
            return
    
    # Log other errors
    print(f"Command error: {error}")

# Help command
@bot.command(name='help')
async def help_command(ctx):
    faq_data = load_faq()
    total_questions = len(faq_data['faq'])
    
    help_text = f"""ü§ñ **AI Kursassistent - Hj√§lp**

**St√§ll VILKEN fr√•ga som helst om AI/ML:**
‚Ä¢ `!vad √§r cursor?`
‚Ä¢ `!jag skulle vilja veta mer om en ai f√∂rst√§rkt ide`
‚Ä¢ `!f√∂rklara deep learning f√∂r nyb√∂rjare`
‚Ä¢ `!vad √§r skillnaden mellan CNN och RNN?`
‚Ä¢ `!hur fungerar transformers?`
‚Ä¢ `!deadline` - Kurs-specifik info
‚Ä¢ `!betyg` - Betygskriterier

**System-kommandon:**
‚Ä¢ `!help` - Visa denna hj√§lp
‚Ä¢ `!info` - Information om botten
‚Ä¢ `!ai-status` - Kontrollera AI-status

**S√• h√§r fungerar det:**
Skriv bara din fr√•ga efter `!` s√• svarar jag med hj√§lp av kursinformation och AI-kunskap.

Totalt {total_questions} FAQ-fr√•gor + obegr√§nsad AI-kunskap! üöÄ"""
    await ctx.send(help_text)

# Info command
@bot.command(name='info')
async def info_command(ctx):
    faq_data = load_faq()
    info_text = f"""‚ÑπÔ∏è **AI Kursassistent Info**

**F√∂rm√•gor:**
‚Ä¢ Svarar p√• ALLA fr√•gor om AI/ML
‚Ä¢ Anv√§nder b√•de kurs-specifik FAQ-data och allm√§n AI-kunskap
‚Ä¢ F√∂rklarar tekniska koncept pedagogiskt
‚Ä¢ Svarar alltid p√• svenska
‚Ä¢ Hanterar b√•de korta och l√•nga fr√•gor

**Teknisk info:**
‚Ä¢ {len(faq_data['faq'])} FAQ-fr√•gor i databasen
‚Ä¢ Anv√§nder Ollama med llama3-modellen
‚Ä¢ F√∂rst√•r naturligt spr√•k och synonymer
‚Ä¢ Inga begr√§nsningar p√• fr√•getyper

Testa att st√§lla vilken fr√•ga som helst! üéØ"""
    await ctx.send(info_text)

# AI-status command
@bot.command(name='ai-status')
async def ai_status(ctx):
    try:
        test_response = ollama.generate(
            model='llama3:latest',
            prompt="Svara bara 'AI fungerar perfekt!' p√• svenska",
            stream=False
        )
        await ctx.send(f"‚úÖ **AI-status: Online**\nüß† Model: llama3")
    except Exception as e:
        await ctx.send(f"‚ùå **AI-status: Offline**\nFel: {e}")

# Hello command
@bot.command(name='hello')
async def hello(ctx):
    await ctx.send(f'Hej {ctx.author.mention}! ü§ñ\n\n‚ú® Jag √§r din AI-kursassistent!\nüß† St√§ll VILKEN fr√•ga som helst om AI/ML\nüí° Exempel: `!vad √§r cursor?` eller `!jag skulle vilja veta mer om transformers`')

# Quick FAQ commands - these now also use the AI system
@bot.command(name='deadline')
async def deadline(ctx):
    await process_question(ctx, "deadline f√∂r projektet")

@bot.command(name='betyg')
async def betyg(ctx):
    await process_question(ctx, "betygskriterier VG och G")

# Event handler for messages
@bot.event
async def on_message(message):
    if message.author == bot.user:
        return
    
    await bot.process_commands(message)

# Run bot
if __name__ == "__main__":
    bot.run(config.BOT_TOKEN)